  ## Machine learning techniques for the analysis of affective components of sign language
  [![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

  ## Description
  In this project, several machine learning techniques were studied to reach a better accuracy for a facial expression recognition model trained on a sign language dataset. Various machine learning techniques such as fine-tuning, data augmentation, class balancing, as well as image preprocessing were used to reach a better accuracy for recognizing the 6 basic Ekman emotions of 'fear', 'disgust', 'surprise', 'sadness', 'happiness', 'anger' along with the 'neutral' class. The models were evaluated using K-fold cross-validation to get a more accurate conclusion. This project also presents a comparison of the above-mentioned techniques based on two different architectures, namely MobileNet and EfficientNet. It is experimentally demonstrated that fine-tuning a pre-trained model along with data augmentation by horizontally flipping images, and applying image normalization, helps in providing the best accuracy on the sign language dataset for both MobileNet and EfficientNet architectures.
  ## Table of Contents
  * [Installation](#installation)
  * [Usage](#usage)
  * [License](#license)
  * [Questions](#questions)
  ## Installation
  numpy==1.19.5
  pandas==1.2.4
  torch==1.9.0+cu102
  opencv_contrib_python==4.5.2.54
  tensorflow==2.5.0
  Pillow==8.3.2
  scikit_learn==1.0

  ## Usage
  This project uses code from [(https://github.com/HSE-asavchenko/face-emotion-recognition)]
  
  ## License
  [![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
  
  https://opensource.org/licenses/Apache-2.0 

  
  ## Questions
  My GitHub: [https://www.github.com/Neha-2](https://github.com/https://www.github.com/Neha-2) <br>
  Email me: nehadeshpande97@gmail.com


